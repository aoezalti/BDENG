{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c99ed9f-1658-46d3-bc29-8377c19e1644",
   "metadata": {},
   "source": [
    "# Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7194c-650f-4ca6-b512-8053d05c4e29",
   "metadata": {},
   "source": [
    "## Install libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d634b-a73f-4e05-95fe-364dd04e12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install libraries & install packages needed to run MongoDB\n",
    "!pip3 install pymongo\n",
    "import pymongo\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "os.environ['PATH'] += os.pathsep + '/usr/local/bin' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ce386-dce6-426a-b11c-4be7b65bc403",
   "metadata": {},
   "source": [
    "## Start Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84f184-251e-41dd-aafb-b48e2070034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c203104-f784-4360-aa47-d27d0859cacb",
   "metadata": {},
   "source": [
    "### Check if the services are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8dfe7-184e-474a-9e31-038cff5e4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f468c3-0318-45b7-bf35-bbe26013b540",
   "metadata": {},
   "source": [
    "## Connect to DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e3c6f-f51a-41a3-bf46-9f11a8e12c33",
   "metadata": {},
   "source": [
    "# Process CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1485d-31d8-4fa7-992b-d78300b23c0f",
   "metadata": {},
   "source": [
    "### Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74418e7-af6b-404e-ae85-2e0e4339ece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997c603-9227-480d-95bc-d14540ee436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Read the CSV file\n",
    "poi_df = pd.read_csv('data/top-locations-wien.csv')\n",
    "\n",
    "# Process the data (e.g., clean, transform)\n",
    "# Here, we will just print the first few rows as an example\n",
    "print(poi_df.head())\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('localhost', 37017)\n",
    "db = client['citybike_vienna']\n",
    "collection = db['top-locations-wien']\n",
    "\n",
    "# Insert data into MongoDB\n",
    "collection.insert_many(poi_df.to_dict('records'))\n",
    "\n",
    "print(\"Data inserted into MongoDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c1124-dc28-4ebb-b940-990e047c3a8d",
   "metadata": {},
   "source": [
    "# Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89771b-9b71-4c0e-8306-17d75ccd6106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session & context\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('nextbike-data-consumer')\n",
    "         .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0\")\n",
    "         .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(\"Spark session created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30513e67-cfb4-40f7-9f6c-c2c40e2e82ed",
   "metadata": {},
   "source": [
    "## Transform and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dbff32-5c59-4257-9185-2ccc97e47504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, from_json, explode\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, ArrayType, LongType\n",
    "\n",
    "# Define schema for the data\n",
    "place_schema = StructType([\n",
    "    StructField(\"uid\", LongType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"bike\", IntegerType(), True),\n",
    "    StructField(\"bike_numbers\", ArrayType(StringType()), True),\n",
    "    StructField(\"free_racks\", IntegerType(), True),\n",
    "    StructField(\"bike_racks\", IntegerType(), True),\n",
    "    StructField(\"lat\", DoubleType(), True),\n",
    "    StructField(\"lng\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "city_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"places\", ArrayType(place_schema), True)\n",
    "])\n",
    "\n",
    "country_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"cities\", ArrayType(city_schema), True)\n",
    "])\n",
    "\n",
    "data_schema = StructType([\n",
    "    StructField(\"countries\", ArrayType(country_schema), True)\n",
    "])\n",
    "\n",
    "# Create stream dataframe setting Kafka server, topic, and offset option\n",
    "df = (spark\n",
    "      .readStream\n",
    "      .format(\"kafka\")\n",
    "      .option(\"kafka.bootstrap.servers\", \"localhost:29093\")  # Kafka server\n",
    "      .option(\"subscribe\", \"nextbike_data\")  # Topic\n",
    "      .option(\"startingOffsets\", \"earliest\")  # Start from beginning\n",
    "      .load())\n",
    "\n",
    "# Convert binary to string key and value\n",
    "df1 = (df\n",
    "       .withColumn(\"key\", df[\"key\"].cast(StringType()))\n",
    "       .withColumn(\"value\", df[\"value\"].cast(StringType())))\n",
    "\n",
    "# Parse JSON data\n",
    "df2 = df1.select(from_json(col(\"value\"), data_schema).alias(\"data\"))\n",
    "\n",
    "# Explode the nested structure to flatten the DataFrame\n",
    "df_countries = df2.select(explode(col(\"data.countries\")).alias(\"country\"))\n",
    "df_cities = df_countries.select(col(\"country.name\").alias(\"country_name\"), explode(col(\"country.cities\")).alias(\"city\"))\n",
    "df_places = df_cities.select(\n",
    "    col(\"country_name\"),\n",
    "    col(\"city.name\").alias(\"city_name\"),\n",
    "    explode(col(\"city.places\")).alias(\"place\")\n",
    ")\n",
    "\n",
    "# Select and rename required fields\n",
    "df_formatted = df_places.select(\n",
    "    col(\"country_name\").alias(\"country\"),\n",
    "    col(\"city_name\").alias(\"city\"),\n",
    "    col(\"place.uid\").alias(\"place_uid\"),\n",
    "    col(\"place.name\").alias(\"place_name\"),\n",
    "    col(\"place.bike\").alias(\"bike\"),\n",
    "    col(\"place.bike_numbers\").alias(\"bike_numbers\"),\n",
    "    col(\"place.free_racks\").alias(\"free_racks\"),\n",
    "    col(\"place.bike_racks\").alias(\"total_racks\"),\n",
    "    col(\"place.lat\").alias(\"latitude\"),\n",
    "    col(\"place.lng\").alias(\"longitude\")\n",
    ")\n",
    "\n",
    "# Show the schema of the dataframe\n",
    "df_formatted.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c217f-321b-4706-971e-d55998a727fb",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7f32f7-c2a3-4dfb-bd7f-3356279d3279",
   "metadata": {},
   "source": [
    "## Visualize the Streaming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86e1f0-d63f-4013-8718-e289cebaa822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query the API and store data\n",
    "def query_api_and_store_data():\n",
    "    url = \"https://api.nextbike.net/maps/nextbike-live.json\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract relevant data\n",
    "        countries = data['countries']\n",
    "        records = []\n",
    "        for country in countries:\n",
    "            for city in country['cities']:\n",
    "                for place in city['places']:\n",
    "                    records.append({\n",
    "                        'country': country['name'],\n",
    "                        'city': city['name'],\n",
    "                        'place_uid': place['uid'],\n",
    "                        'place_name': place['name'],\n",
    "                        'bike': place['bike'],\n",
    "                        'bike_numbers': place.get('bike_numbers', []),\n",
    "                        'free_racks': place.get('free_racks', None),\n",
    "                        'total_racks': place.get('bike_racks', None),\n",
    "                        'latitude': place['lat'],\n",
    "                        'longitude': place['lng'],\n",
    "                    })\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(records)\n",
    "        \n",
    "        # Display the head of the DataFrame\n",
    "        print(df.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "query_api_and_store_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
