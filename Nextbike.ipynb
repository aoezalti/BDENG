{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c99ed9f-1658-46d3-bc29-8377c19e1644",
   "metadata": {},
   "source": [
    "# Citybike Standorte & Nutzungsverhalten in Wien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13626be-b2a1-4c1d-9c0f-2a01fbd23691",
   "metadata": {},
   "source": [
    "In diesem Jupyter Notebook zeigen wir, wie man Wetterdaten und Nextbike-Nutzungsdaten für Wien in Echtzeit scrapt, an Kafka sendet und mit Kafka-Consumer empfängt, um sie anschließend grafisch darzustellen. Dies umfasst das Scrapen von Wetterdaten von einer Webseite, das Abrufen von Nextbike-Daten über eine API, das Senden der Daten an Kafka-Topics und die Visualisierung der Daten als interaktive App und in Graphen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9783cf-40b1-4800-b37c-d27ac7b3d2f5",
   "metadata": {},
   "source": [
    "### Datasources:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc45990-0a16-490b-bf4e-388fb507cef1",
   "metadata": {},
   "source": [
    "- API von Nextbike zur Ermittlung der Nextbike Standorte und Auslastung\n",
    "  https://api.nextbike.net/maps/nextbike-live.json\n",
    "- Webscraping zum Scrapen der (historischen) Wetterdaten für Wien\n",
    "  https://www.wunderground.com/history/daily/at/vienna\n",
    "- POIs (Point of Interest) in Wien\n",
    "  https://www.data.gv.at/katalog/dataset/f4e80988-c139-4953-8176-b3d6d03f6449"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71788196-53c3-4e57-b96a-4118aa803443",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5096b3f6-f6ff-49fa-a519-5c24f17661ce",
   "metadata": {},
   "source": [
    "![Alt Text](Slide2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb78ba5-9e19-4901-bc84-48cdaadf8894",
   "metadata": {},
   "source": [
    "github: https://github.com/aoezalti/BDENG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7194c-650f-4ca6-b512-8053d05c4e29",
   "metadata": {},
   "source": [
    "## Install libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d634b-a73f-4e05-95fe-364dd04e12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install libraries & install packages needed to run MongoDB\n",
    "import requests\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "os.environ['PATH'] += os.pathsep + '/usr/local/bin' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ce386-dce6-426a-b11c-4be7b65bc403",
   "metadata": {},
   "source": [
    "## Start Docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84f184-251e-41dd-aafb-b48e2070034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker-compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c203104-f784-4360-aa47-d27d0859cacb",
   "metadata": {},
   "source": [
    "### Check if the services are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8dfe7-184e-474a-9e31-038cff5e4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e3c6f-f51a-41a3-bf46-9f11a8e12c33",
   "metadata": {},
   "source": [
    "# Process CSV Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94647470-1f15-4e2e-9a38-632560711ba7",
   "metadata": {},
   "source": [
    "### Read data and display the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f2bf2-f3e7-47b8-a61d-4a430ee5a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file with the specified encoding\n",
    "poi_df = pd.read_csv('data/top-locations-wien.csv', encoding='latin1', sep=';')\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(poi_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d95539-2a5d-4134-8866-722ed7aa67e1",
   "metadata": {},
   "source": [
    "### Create new DataFrame for the Vizualisation (category and coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c779e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswahl der gewünschten Spalten\n",
    "new_df = poi_df[['category', 'geo_latitude', 'geo_longitude']]\n",
    "# Ausgabe des neuen DataFrames\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20983d77-8eaf-4b9d-ad47-07bffacddf0b",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dd5e8-e323-49ca-b1a6-022e30cb3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f2c83-6a41-469b-a497-ca94c66d3fc7",
   "metadata": {},
   "source": [
    "## CSV-Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24ca26-e730-4d9a-90fc-e8758690b01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill or drop missing values\n",
    "new_df = new_df.dropna()  # Dropping rows with missing values\n",
    "\n",
    "# Check for duplicates\n",
    "print(new_df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "new_df = new_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2716d6e3-35c5-45e3-9630-84ce1741e774",
   "metadata": {},
   "source": [
    "### Show clean Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715ed90-4841-42c6-981c-8b78c479bfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151e6cb-2226-42fa-8b02-eabbc7f94e02",
   "metadata": {},
   "source": [
    "## Save data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01837fe-db66-4fa3-9e9d-05d42fe6c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speichern des DataFrames als CSV-Datei mit richtiger Spaltenstruktur\n",
    "new_df.to_csv('data/poi_coordinates.csv', index=False, sep=';')\n",
    "\n",
    "print(\"Datei wurde erfolgreich im 'data'-Ordner gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9940b7-add3-4630-ba96-69ccc1b59a52",
   "metadata": {},
   "source": [
    "## Analyse and Vizualisation of CSV-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6047de-a3ce-45d3-ae82-1f1b030a081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas matplotlib seaborn folium geopandas shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2605bf-c0b8-4b65-821b-44f8a9046ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Gegebene Daten für Kategorien und Koordinaten\n",
    "data = pd.read_csv('data/poi_coordinates.csv', encoding='latin1', sep=';')\n",
    "\n",
    "# DataFrame erstellen\n",
    "new_df = pd.DataFrame(data)\n",
    "\n",
    "# Filtern nach den gewünschten Kategorien\n",
    "desired_categories = ['museum', 'shopping', 'cafes', 'musicstage', \n",
    "                      'restaurants', 'sightseeing', 'nightlife', \n",
    "                      'gastronomy', 'accommodations']\n",
    "new_df['category'] = new_df['category'].str.lower()  # Konvertierung zu Kleinbuchstaben für die Kategorienvergleich\n",
    "new_df = new_df[new_df['category'].isin(desired_categories)]\n",
    "\n",
    "# Konvertierung der Koordinaten von Strings zu Floats\n",
    "new_df['geo_latitude'] = new_df['geo_latitude'].str.replace(',', '.').astype(float)\n",
    "new_df['geo_longitude'] = new_df['geo_longitude'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Grundlegende Analyse\n",
    "print(new_df.describe())\n",
    "print(new_df['category'].value_counts())\n",
    "\n",
    "# Visualisierung der Verteilung der Kategorien mit Matplotlib und Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=new_df, x='category', palette='viridis')\n",
    "plt.title('Verteilung der Kategorien')\n",
    "plt.xlabel('Kategorie')\n",
    "plt.ylabel('Anzahl')\n",
    "plt.show()\n",
    "\n",
    "# Erstellen einer Karte für Wien mit Folium\n",
    "map_vienna = folium.Map(location=[48.210033, 16.363449], zoom_start=13)\n",
    "\n",
    "# MarkerCluster für eine bessere Darstellung von dichten Markergruppen\n",
    "marker_cluster = MarkerCluster().add_to(map_vienna)\n",
    "\n",
    "# Funktion zur Zuordnung von Farben basierend auf der Kategorie\n",
    "def get_color(category):\n",
    "    if category == 'museum':\n",
    "        return 'purple'\n",
    "    elif category == 'shopping':\n",
    "        return 'blue'\n",
    "    elif category == 'cafes':\n",
    "        return 'green'\n",
    "    elif category == 'musicstage':\n",
    "        return 'orange'\n",
    "    elif category == 'restaurants':\n",
    "        return 'red'\n",
    "    elif category == 'sightseeing':\n",
    "        return 'darkblue'\n",
    "    elif category == 'nightlife':\n",
    "        return 'darkred'\n",
    "    elif category == 'gastronomy':\n",
    "        return 'lightgreen'\n",
    "    elif category == 'accommodations':\n",
    "        return 'cadetblue'\n",
    "    else:\n",
    "        return 'gray'  # Fallback für unbekannte Kategorien\n",
    "\n",
    "# Hinzufügen der POI-Marker zur Karte\n",
    "for _, row in new_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['geo_latitude'], row['geo_longitude']],\n",
    "        popup=row['category'].capitalize(),\n",
    "        icon=folium.Icon(color=get_color(row['category']))\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Speichern der Karte als HTML-Datei\n",
    "map_vienna.save('data/poi_map_vienna1.html')\n",
    "\n",
    "# Ausgabe, um den Benutzer darüber zu informieren, dass die Karte gespeichert wurde\n",
    "print(\"Die Karte wurde erfolgreich als 'poi_map_vienna.html' gespeichert.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff9830-ce49-4707-b30c-f41c10c323fd",
   "metadata": {},
   "source": [
    "# Kafka Producer & Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d519c5-fa73-47cd-b0ef-ea68c68ef4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load important libraries\n",
    "from kafka import KafkaProducer\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "# Create Kafka producer\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:29093'],\n",
    "                         value_serializer=lambda v: json.dumps(v).encode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8e0b3-66ee-4e4d-9d7f-1f60032a2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Gegebene Daten für Kategorien und Koordinaten\n",
    "data = pd.read_csv('data/poi_coordinates.csv', encoding='latin1', sep=';')\n",
    "\n",
    "# DataFrame erstellen\n",
    "new_df = pd.DataFrame(data)\n",
    "\n",
    "# Filtern nach den gewünschten Kategorien\n",
    "desired_categories = ['museum', 'shopping', 'cafes', 'musicstage', \n",
    "                      'restaurants', 'sightseeing', 'nightlife', \n",
    "                      'gastronomy', 'accommodations']\n",
    "new_df['category'] = new_df['category'].str.lower()  # Konvertierung zu Kleinbuchstaben für die Kategorienvergleich\n",
    "new_df = new_df[new_df['category'].isin(desired_categories)]\n",
    "\n",
    "# Bereinigung der Koordinaten\n",
    "new_df['geo_latitude'] = new_df['geo_latitude'].str.replace(',', '.')\n",
    "new_df['geo_longitude'] = new_df['geo_longitude'].str.replace(',', '.')\n",
    "\n",
    "# Entfernen von Zeilen mit ungültigen Koordinaten\n",
    "new_df = new_df[new_df['geo_latitude'].apply(lambda x: x.replace('.', '', 1).isdigit())]\n",
    "new_df = new_df[new_df['geo_longitude'].apply(lambda x: x.replace('.', '', 1).isdigit())]\n",
    "\n",
    "# Konvertieren der Koordinaten in das richtige Format\n",
    "new_df['geo_latitude'] = new_df['geo_latitude'].astype(float)\n",
    "new_df['geo_longitude'] = new_df['geo_longitude'].astype(float)\n",
    "\n",
    "# Debug-Ausgabe nach der Konvertierung\n",
    "print(\"Nach der Konvertierung:\")\n",
    "print(new_df[['geo_latitude', 'geo_longitude']].head())\n",
    "print(new_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becbf316-7bb7-4237-b11f-10f415cb9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "print(new_df.head())\n",
    "print(new_df.dtypes)\n",
    "# REST API URL\n",
    "api_url = 'https://api.nextbike.net/maps/nextbike-live.json'\n",
    "\n",
    "def fetch_data():\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Fehler beim Abrufen der Daten: {e}\")\n",
    "        return None\n",
    "\n",
    "nextbike_data = fetch_data()\n",
    "\n",
    "# Beispielstruktur: Daten verarbeiten\n",
    "wien_data = []\n",
    "\n",
    "if nextbike_data is not None:\n",
    "    for country in nextbike_data.get('countries', []):\n",
    "        if country.get('country_name') == 'Austria':\n",
    "            for city in country.get('cities', []):\n",
    "                if city.get('name') == 'Wien':\n",
    "                    for place in city.get('places', []):\n",
    "                         if not place.get('name', '').startswith('BIKE'):\n",
    "                            station_data = {\n",
    "                                'station': place.get('name'),\n",
    "                                'geo_latitude': str(place.get('lat')).replace(',', '.'),\n",
    "                                'geo_longitude': str(place.get('lng')).replace(',', '.'),\n",
    "                                'available_bikes': place.get('bikes')\n",
    "                            }\n",
    "                            wien_data.append(station_data)\n",
    "\n",
    "# Umwandlung in ein Pandas DataFrame\n",
    "wien_df = pd.DataFrame(wien_data)\n",
    "wien_df['geo_latitude'] = wien_df['geo_latitude'].astype(float)\n",
    "wien_df['geo_longitude'] = wien_df['geo_longitude'].astype(float)\n",
    "\n",
    "# Entfernen der ersten Zeile\n",
    "wien_df = wien_df.drop(index=0).reset_index(drop=True)\n",
    "\n",
    "# dataframe als csv speichern\n",
    "csv_file_path = 'data/wien_data.csv'\n",
    "wien_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Überprüfen der Spaltennamen und Daten\n",
    "print(\"Wien DataFrame:\")\n",
    "print(wien_df.head())\n",
    "print(wien_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fed7a3-14b1-4135-9c1f-406cdfab4a2f",
   "metadata": {},
   "source": [
    "# Set up Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3c9bcd-20a4-4d77-aeaa-78f635b35ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb3c2f0-501e-490b-922d-e7719988ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaSparkStream\") \\\n",
    "    .master(\"spark://172.29.16.102:7077\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082a28b-a975-4901-b561-f4f61e1059ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertiere Pandas DataFrame in Spark RDD\n",
    "wien_rdd = sc.parallelize(wien_df.to_dict(orient='records'))\n",
    "\n",
    "print(\"Inhalt des Wien RDD:\")\n",
    "for record in wien_rdd.take(5):\n",
    "    print(record)\n",
    "\n",
    "# Zählen der Anzahl der Stationen\n",
    "station_count = wien_rdd.count()\n",
    "print(f\"Anzahl der Stationen: {station_count}\")\n",
    "\n",
    "# durchschnittliche Anzahl der verfügbaren Fahrräder pro Station\n",
    "average_bikes = wien_rdd.map(lambda x: x['available_bikes']).mean()\n",
    "print(f\"Durchschnittliche Anzahl der verfügbaren Fahrräder pro Station: {average_bikes}\")\n",
    "\n",
    "# Verteilung der verfügbaren Fahrräder pro Station\n",
    "bikes_distribution = wien_rdd.map(lambda x: (x['station'], x['available_bikes'])).collect()\n",
    "print(\"Verteilung der verfügbaren Fahrräder pro Station:\")\n",
    "for station, bikes in bikes_distribution:\n",
    "    print(f\"Station: {station}, Verfügbare Fahrräder: {bikes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a2f4c4-7762-4d57-8e51-855d4b6f2e86",
   "metadata": {},
   "source": [
    "### Experimentieren mit Spark RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c360a-1f0f-4159-b20f-49ec84f06a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: CSV-Datei laden\n",
    "file_path = \"data/poi_coordinates.csv\"  # Pfad zu Ihrer CSV-Datei\n",
    "rdd = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "header = rdd.first()\n",
    "data_rdd = rdd.filter(lambda row: row != header)\n",
    "\n",
    "# Daten aufteilen und analysieren\n",
    "data_rdd = data_rdd.map(lambda row: row.split(','))  # Annahme: CSV ist komma-separiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817bde51-a538-47ec-8bc9-5eafe854faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielanalyse: Zählen der Anzahl von Einträgen pro Kategorie\n",
    "category_counts = data_rdd.map(lambda x: (x[0], 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(\"Anzahl der Einträge pro Kategorie:\")\n",
    "for category, count in category_counts.collect():\n",
    "    print(f\"{category}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ea24d-f5f5-411a-802e-4dba57be50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka-Parameter\n",
    "kafka_bootstrap_servers = 'localhost:29093'\n",
    "kafka_topic = 'nextbike_wien'\n",
    "\n",
    "# Definieren des Schemas für die JSON-Daten\n",
    "schema = StructType([\n",
    "    StructField(\"station\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"available_bikes\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Daten von Kafka lesen\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "df = df.selectExpr(\"CAST(value AS STRING)\")\n",
    "df = df.withColumn(\"jsonData\", from_json(col(\"value\"), schema)).select(\"jsonData.*\")\n",
    "\n",
    "# Streaming-Daten in der Konsole anzeigen\n",
    "query = df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfa7e9-27f9-418a-ac9a-9a4bb704214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20af658-7962-4ba2-81dc-dbd1ce943d6a",
   "metadata": {},
   "source": [
    "# Karte mit POIs und Nextbike-Stationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57ebe5-97a1-4daa-97b3-8d2aff73b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Erstellen einer Karte für Wien mit Folium\n",
    "map_vienna = folium.Map(location=[48.210033, 16.363449], zoom_start=13)\n",
    "\n",
    "# MarkerCluster für eine bessere Darstellung von dichten Markergruppen\n",
    "poi_marker_cluster = MarkerCluster().add_to(map_vienna)\n",
    "nextbike_marker_cluster = MarkerCluster().add_to(map_vienna)\n",
    "\n",
    "# Funktion zur Zuordnung von Farben basierend auf der Kategorie\n",
    "def get_color(category):\n",
    "    if category == 'museum':\n",
    "        return 'purple'\n",
    "    elif category == 'shopping':\n",
    "        return 'blue'\n",
    "    elif category == 'cafes':\n",
    "        return 'green'\n",
    "    elif category == 'musicstage':\n",
    "        return 'orange'\n",
    "    elif category == 'restaurants':\n",
    "        return 'red'\n",
    "    elif category == 'sightseeing':\n",
    "        return 'darkblue'\n",
    "    elif category == 'nightlife':\n",
    "        return 'darkred'\n",
    "    elif category == 'gastronomy':\n",
    "        return 'lightgreen'\n",
    "    elif category == 'accommodations':\n",
    "        return 'cadetblue'\n",
    "    else:\n",
    "        return 'gray'  # Fallback für unbekannte Kategorien\n",
    "\n",
    "# POI-Marker\n",
    "for _, row in new_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['geo_latitude'], row['geo_longitude']],\n",
    "        popup=row['category'].capitalize(),\n",
    "        icon=folium.Icon(color=get_color(row['category']))\n",
    "    ).add_to(poi_marker_cluster)\n",
    "\n",
    "# Nextbike-Stationen\n",
    "for _, row in wien_df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['geo_latitude'], row['geo_longitude']],\n",
    "        popup=f\"Station: {row['station']}, Available bikes: {row['available_bikes']}\",\n",
    "        icon=folium.Icon(color='pink', icon='bicycle', prefix='fa')  # Verwenden Sie ein anderes Symbol und eine andere Farbe\n",
    "    ).add_to(nextbike_marker_cluster)\n",
    "\n",
    "# Speichern der Karte als HTML-Datei\n",
    "map_vienna.save('data/poi_map_vienna2.html')\n",
    "\n",
    "print(\"Die Karte wurde erfolgreich als 'poi_map_vienna2.html' gespeichert.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812bf94-7669-4f3a-b224-3d397a9fbecc",
   "metadata": {},
   "source": [
    "# Zuordnung bei welchen Kategorien die meisten Nextbike-Stationen sind "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949c19d-1df3-4334-9cfa-0475b1c68b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Konvertieren der Koordinaten in floats\n",
    "poi_df['geo_latitude'] = poi_df['geo_latitude'].str.replace(',', '.').astype(float)\n",
    "poi_df['geo_longitude'] = poi_df['geo_longitude'].str.replace(',', '.').astype(float)\n",
    "\n",
    "# Erstellen von GeoDataFrames\n",
    "poi_gdf = gpd.GeoDataFrame(poi_df, geometry=gpd.points_from_xy(poi_df.geo_longitude, poi_df.geo_latitude))\n",
    "\n",
    "print(\"POI GeoDataFrame nach der Konvertierung:\")\n",
    "print(poi_gdf[['geo_latitude', 'geo_longitude', 'category']].head())\n",
    "print(poi_gdf.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a118e2-d12e-4427-adab-54c158e0ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertieren der Koordinaten in das richtige Format\n",
    "wien_df['geo_latitude'] = wien_df['geo_latitude'].astype(float)\n",
    "wien_df['geo_longitude'] = wien_df['geo_longitude'].astype(float)\n",
    "\n",
    "# Erstellen von GeoDataFrames für Nextbike-Stationen\n",
    "wien_gdf = gpd.GeoDataFrame(wien_df, geometry=gpd.points_from_xy(wien_df.geo_longitude, wien_df.geo_latitude))\n",
    "\n",
    "print(wien_gdf[['geo_latitude', 'geo_longitude', 'station']].head())\n",
    "print(wien_gdf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f1584-9850-49f2-b6e5-9c584c8646ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_gdf.set_crs(epsg=4326, inplace=True, allow_override=True)\n",
    "wien_gdf.set_crs(epsg=4326, inplace=True, allow_override=True)\n",
    "\n",
    "buffer_radius = 1500  # 1500 Meter\n",
    "\n",
    "# Projektion in ein metrisches System (z.B. UTM) für das Erstellen der Puffer\n",
    "poi_gdf = poi_gdf.to_crs(epsg=32633)  # UTM Zone 33N für Wien\n",
    "wien_gdf = wien_gdf.to_crs(epsg=32633)\n",
    "\n",
    "# Erstellen der Puffer um die POIs\n",
    "poi_gdf['buffer'] = poi_gdf.geometry.buffer(buffer_radius)\n",
    "\n",
    "poi_gdf.set_geometry('buffer', inplace=True)\n",
    "\n",
    "joined_gdf = gpd.sjoin(wien_gdf, poi_gdf[['category', 'buffer']], predicate='within')\n",
    "\n",
    "# Zähle die Anzahl der Nextbike-Stationen in der Nähe jeder POI-Kategorie\n",
    "category_station_counts = joined_gdf.groupby('category').size().reset_index(name='station_count')\n",
    "\n",
    "print(\"Anzahl der Nextbike-Stationen in der Nähe jeder POI-Kategorie:\")\n",
    "print(category_station_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cfea3c-e496-4511-aac1-cdd49c12e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualisieren der Anzahl der Nextbike-Stationen in der Nähe jeder POI-Kategorie\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=category_station_counts, x='category', y='station_count', palette='viridis')\n",
    "plt.title('Anzahl der Nextbike-Stationen in der Nähe jeder POI-Kategorie')\n",
    "plt.xlabel('Kategorie')\n",
    "plt.ylabel('Anzahl der Stationen')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46a785-4a84-42ea-9025-306f62216685",
   "metadata": {},
   "source": [
    "# Experiment: Wetterdaten & Bike Nutzung plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59661e-7832-49d6-83a2-43f44eb89a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Kafka Consumer für Wetterdaten\n",
    "weather_consumer = KafkaConsumer(\n",
    "    'weather-data',\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    group_id='weather-group',\n",
    "    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n",
    ")\n",
    "\n",
    "# Kafka Consumer für Nextbike-Daten\n",
    "nextbike_consumer = KafkaConsumer(\n",
    "    'nextbike_wien',\n",
    "    bootstrap_servers='localhost:9092',\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    group_id='nextbike-group',\n",
    "    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n",
    ")\n",
    "\n",
    "# DataFrames zum Speichern der empfangenen Daten\n",
    "weather_data = pd.DataFrame(columns=['Zeit', 'Temperatur'])\n",
    "nextbike_data = pd.DataFrame(columns=['station', 'geo_latitude', 'geo_longitude', 'available_bikes'])\n",
    "\n",
    "# Funktion zum Aktualisieren der Plots\n",
    "def update_plots():\n",
    "    global weather_data, nextbike_data\n",
    "    \n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Plot für die Temperaturdaten\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.lineplot(data=weather_data, x='Zeit', y='Temperatur')\n",
    "    plt.title('Temperaturverlauf')\n",
    "    plt.xlabel('Zeit')\n",
    "    plt.ylabel('Temperatur (°C)')\n",
    "\n",
    "    # Plot für die Nextbike-Nutzung\n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.lineplot(data=nextbike_data, x='Zeit', y='available_bikes')\n",
    "    plt.title('Nextbike-Nutzung')\n",
    "    plt.xlabel('Zeit')\n",
    "    plt.ylabel('Verfügbare Fahrräder')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Funktion zum Empfangen der Wetterdaten\n",
    "def consume_weather_data():\n",
    "    global weather_data\n",
    "    for message in weather_consumer:\n",
    "        data = message.value\n",
    "        data['Zeit'] = datetime.strptime(data['Zeit'], '%H:%M')\n",
    "        data['Temperatur'] = float(data['Temperatur'].replace('°C', '').strip())\n",
    "        weather_data = weather_data.append(data, ignore_index=True)\n",
    "        if len(weather_data) > 500:\n",
    "            weather_data = weather_data[-500:]\n",
    "        update_plots()\n",
    "\n",
    "# Funktion zum Empfangen der Nextbike-Daten\n",
    "def consume_nextbike_data():\n",
    "    global nextbike_data\n",
    "    for message in nextbike_consumer:\n",
    "        data = message.value\n",
    "        data['Zeit'] = datetime.now()\n",
    "        nextbike_data = nextbike_data.append(data, ignore_index=True)\n",
    "        if len(nextbike_data) > 500: \n",
    "            nextbike_data = nextbike_data[-500:]\n",
    "        update_plots()\n",
    "\n",
    "# Starten der Consumer in separaten Threads\n",
    "from threading import Thread\n",
    "\n",
    "weather_thread = Thread(target=consume_weather_data)\n",
    "nextbike_thread = Thread(target=consume_nextbike_data)\n",
    "\n",
    "weather_thread.start()\n",
    "nextbike_thread.start()\n",
    "\n",
    "weather_thread.join()\n",
    "nextbike_thread.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
